<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="How Can Objects Help Video-Language Understanding?">
  <meta property="og:title" content="How Can Objects Help Video-Language Understanding?"/>
  <meta property="og:description" content="How Can Objects Help Video-Language Understanding?"/>
  <meta property="og:url" content="https://brown-palm.github.io/ObjectMLLM/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/favicon.ico" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>How Can Objects Help Video-Language Understanding?</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title"><a href="https://iccv.thecvf.com/Conferences/2025" target="_blank">ICCV 2025</a></h1>
            <h1 class="title is-2 publication-title">How Can Objects Help Video-Language Understanding?</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://zitiantang.github.io/" target="_blank">Zitian Tang</a>,&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://wang-sj16.github.io/" target="_blank">Shijie Wang</a>,&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://brown-palm.github.io/ObjectMLLM/" target="_blank">Junho Cho</a>,&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://brown-palm.github.io/ObjectMLLM/" target="_blank">Jaewook Yoo</a>,&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://chensun.me/" target="_blank">Chen Sun</a>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Brown University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
                    <span class="author-block">Samsung Electronics</span>
                    <!-- span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span -->
                  </div>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2504.07454" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/brown-palm/ObjectMLLM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">

        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            How multimodal large language models (MLLMs) perceive the visual world remains a mystery. To one extreme, object and relation modeling may be implicitly implemented with inductive biases, for example by treating objects as tokens. To the other extreme, empirical results reveal the surprising finding that simply performing visual captioning, which tends to ignore spatial configuration of the objects, serves as a strong baseline for video understanding. We aim to answer the question: how can objects help video-language understanding in MLLMs? We tackle the question from the object representation and adaptation perspectives. Specifically, we investigate the trade-off between representation expressiveness (e.g., distributed versus symbolic) and integration difficulty (e.g., data-efficiency when learning the adapters). Through extensive evaluations on five video question answering datasets, we confirm that explicit integration of object-centric representation remains necessary, and the symbolic objects can be most easily integrated while being performant for question answering. We hope our findings can encourage the community to explore the explicit integration of perception modules into MLLM design.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">

            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">

            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">

            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\

            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->

<!-- Intro-->
<section class="hero is-small">
  <div class="hero-body" style="font-size: large;">
    <div class="container is-max-widescreen">
      <h2 class="title is-3" style="width: 100%; margin: 0 auto;">Motivation</h2>
      <br>
      <p style="text-align: justify; width: 90%; margin: 0 auto;">
          In the era of MLLMs, anything that can be tokenized has the potential to serve as a valid representation.
          Along the spectrum are two extremes: those that project arbitrary distributed representations to the input space of LLMs, and those that model the visual world as interpretable concepts or captions.
          It is open to debate whether they can effectively convey the complexity of the visual world to an LLM reasoner.
          For example, video captions may struggle to describe the spatial and temporal configurations of objects.
          We hypothesize that explicit object-centric recognition and modeling remains essential to the success of MLLMs. We seek to answer the question, <b>how can objects help video-language understanding in MLLMs</b>, from two perspectives: <b>representation and adaptation</b>. 
        </p>
      <br> 
      <img src="static/images/teaser.png" alt="annotation" style="width: 90%; height: auto; display: block; margin: 0 auto;"/>
    </div>
  </div>
</section>
<!-- End Intro-->
<hr>

<section class="hero is-small">
  <div class="hero-body" style="font-size: large;">
    <div class="container is-max-widescreen">
      <h2 class="title is-3" style="width: 100%; margin: 0 auto;">ObjectMLLM</h2>
      <br>
      <p style="text-align: justify; width: 90%; margin: 0 auto;">
        We propose <b>ObjectMLLM</b>, a multimodal framework integrating <b>distributed visual embeddings, video frame captions, and object bounding boxes</b> into one MLLM.
        With external object detection and tracking models, we capture object bounding boxes from videos.
        Then we feed the object labels, timestamps, and bounding boxes to the model. The model backbone can be either an LLM (e.g., LLaMA3) or MLLM (e.g., VideoLLaMA2).
        <br>
        We explore two choices of bounding box adapters.
        The language-based representation naturally represents the bounding boxes as texts, while the embedding projector learns a projection from the bounding box space to LLM input space.
      </p>
      <br> 
      <img src="static/images/model.png" alt="annotation" style="width: 90%; height: auto; display: block; margin: 0 auto;"/>
    </div>
  </div>
</section>
<hr>

<section class="hero is-small">
  <div class="hero-body" style="font-size: large;">
    <div class="container is-max-widescreen">
      <h2 class="title is-3" style="width: 100%; margin: 0 auto;">Experiments</h2>
      <br>
      <p style="text-align: justify; width: 90%; margin: 0 auto;">
          <b>Language-based representation adapts bounding boxes better.</b>
          We evaluate the two choices of obejct bounding box adapter across various sizes of training data.
          The language-based representation consistently outperforms the embedding projector, indicating its effectiveness and data-efficiency.
        </p>
      <br> 
      <img src="static/images/adapter_comparison.png" alt="annotation" style="width: 50%; height: auto; display: block; margin: 0 auto;"/>
      <br>
      <p style="text-align: justify; width: 90%; margin: 0 auto;">
          <b>Object bounding boxes improve spatio-temporal understanding.</b>
          We evaluate ObjectMLLM on five Video QA benchmarks with different combinations of representations.
          The object bounding boxes especially improve the model performance on CLEVRER-MC, Perception Test, and STAR, which have questions related to spatio-temporal object configurations.
      </p>
      <br> 
      <img src="static/images/modality_ablation.png" alt="annotation" style="width: 70%; height: auto; display: block; margin: 0 auto;"/>
      <br>
      <p style="text-align: justify; width: 90%; margin: 0 auto;">
          <b>Main results.</b> Compared with previous works, ObjectMLLM outperforms them by a large margin on CLEVRER-MC and Perception Test, and achieves comparable performance on other benchmarks.
      </p>
      <br> 
      <img src="static/images/main_results.png" alt="annotation" style="width: 80%; height: auto; display: block; margin: 0 auto;"/>
    </div>
  </div>
</section>
<hr>

<section class="hero is-small">
  <div class="hero-body" style="font-size: large;">
    <div class="container is-max-widescreen">
      <h2 class="title is-3" style="width: 100%; margin: 0 auto;">Qualitative Results</h2>
      <br>
      <h3 class="title is-4 has-text-centered">CLEVRER</h3>
      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/clevrer.mp4" type="video/mp4"> <!-- clevrer_video_13709_599 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/clevrer_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> How many moving metal objects are there?<br>
        <b>(A)</b> 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <b>(B)</b> 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <b>(C)</b> 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <span style="color: green;"><b>(D)</b> 4 &check;</span><br>
      </p>
      <h3 class="title is-4 has-text-centered">Perception Test</h3>
      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_1.mp4" type="video/mp4"> <!-- PT_video_171_0 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_1_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> What happened once the person removed an object from the tabletop?<br>
        <b>(A)</b> The launched object fell off the table.<br>
        <span style="color: green;"><b>(B)</b> The launched object did not fall off the table. &check;</span><br>
        <b>(C)</b> No object was removed from the tabletop.<br>
      </p>
      <br>

      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_2.mp4" type="video/mp4"> <!-- PT_video_145_0 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_2_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> Is the camera moving or static?<br>
        <span style="color: green;"><b>(A)</b> Moving. &check;</span><br>
        <b>(B)</b> Static or shaking.<br>
        <b>(C)</b> I don't know.<br>
      </p>
      <br>

      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_3.mp4" type="video/mp4"> <!-- PT_video_1539_0 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_3_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> Is the configuration of objects likely to be stable after placing the last object?<br>
        <b>(A)</b> One cannot judge the stability of this configuration.<br>
        <span style="color: green;"><b>(B)</b> The configuration is likely to be stable. &check;</span><br>
        <b>(C)</b> The configuration is likely to be unstable.<br>
      </p>
      <br>

      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_4.mp4" type="video/mp4"> <!-- PT_video_5497_3 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_4_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> What object does the person use to hit other objects?<br>
        <b>(A)</b> pen&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <b>(B)</b> fork&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <span style="color: green;"><b>(C)</b> spoon &check;</span><br>
      </p>
      <br>

      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_5.mp4" type="video/mp4"> <!-- PT_video_394_1 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/ptest_5_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> Is there something unusual about the way the person ties the shoe laces?<br>
        <b>(A)</b> The person ties correctly the left shoe lace, but not the right shoe lace.<br>
        <span style="color: red;"><b>(B)</b> The person ties the shoe laces normally. &#10060;</span><br>
        <span style="color: green;"><b>(C)</b> The person ties the lace of the left shoe to the lace of the right shoe.</span><br>
      </p>
      <br>

      <h3 class="title is-4 has-text-centered">NExT-QA</h3>
      <div class="columns is-centered" style="width: 80%; margin: 0 auto;">
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/nextqa.mp4" type="video/mp4"> <!-- nextqa_5256928210_9 -->
          </video>
          <h3 class="subtitle is-5">Input Video</h3>
        </div>
        <div class="column is-half has-text-centered">
          <video controls width="90%">
            <source src="static/videos/nextqa_box.mp4" type="video/mp4">
          </video>
          <h3 class="subtitle is-5">Detected and Tracked Objects</h3>
        </div>
      </div>
      <p style="text-align: justify; width: 80%; margin: 0 auto;">
        <b>Question:</b> Why is the man kneeling down on the floor?<br>
        <span style="color: red;"><b>(A)</b> Feed the dog. &#10060;</span><br>
        <b>(B)</b> Crawling around.<br>
        <b>(C)</b> Let kids walk through.<br>
        <b>(D)</b> Fell down.<br>
        <span style="color: green;"><b>(E)</b> Pet the dog.</span><br>
      </p>
    </div>
  </div>
</section>
<hr>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-widescreen">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{tang2025objectmllm,
    title={How Can Objects Help Video-Language Understanding?}, 
    author={Zitian Tang and Shijie Wang and Junho Cho and Jaewook Yoo and Chen Sun},
    year={2025},
    eprint={2504.07454},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
  </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
